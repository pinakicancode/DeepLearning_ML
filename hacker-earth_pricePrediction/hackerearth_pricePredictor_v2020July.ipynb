{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Problem: Predict the lowest price\nCompetition: Hackerearth<br>\nProblem Statement: https://www.hackerearth.com/problem/machine-learning/predict-the-lowest-price-8-9ffabe00/<br>\nAuthor: Pinaki Brahma<br>\n> Performance: 99.83% accuracy on final submission (Top 5 %ile)<br>\n> Methodology: Python based solution. A FastAi approach to solve Tabular Data powered by GPU"},{"metadata":{},"cell_type":"markdown","source":"# Set Up Envirionment"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load necessary packages"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from fastai.tabular import *\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/Train.csv')\nX_test = pd.read_csv('/kaggle/input/Test.csv')\ndf.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Separate the dependent & the independent variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Low_Cap_Price'], axis = 1)\ny = pd.DataFrame(df.Low_Cap_Price)\n\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature Design Section"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Date related features are added to the dataset\nadd_datepart(X, \"Date\", drop=False)\nadd_datepart(X_test, \"Date\", drop=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for columns\nX.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical & Continuous variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"dep_var = ['Low_Cap_Price']\n# cont_names, cat_names = cont_cat_split(df=X, max_card=6, dep_var=dep_var)\ncont_names = ['Demand', 'High_Cap_Price']\ncat_names = ['State_of_Country', 'Market_Category', 'Product_Category', 'Grade', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear']\ndep_var, cont_names, cat_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Explicitly Scaling features | if necessary"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n\n## scale continuous features\n# X_cont = X[cont_names]\n# print(X_cont.describe())\n\n# sc_X = StandardScaler()\n# X_cont = pd.DataFrame(sc_X.fit_transform(X_cont))\n# X_test_cont = pd.DataFrame(sc_X.transform(X_test[cont_names]))\n# X_cont.columns = cont_names\n# X_test_cont.columns = cont_names\n\n# sc_y = StandardScaler()\n# y_sc = pd.DataFrame(sc_y.fit_transform(y))\n# y_sc.columns = dep_var\n\n# print(X_cont.head())\n# print(y_sc[0:5])\n# print(X_test_cont.head())\n\n## --- merge categorical features back ---\n# X_all = pd.concat([X[cat_names], X_cont], axis = 1) X_test_all = pd.concat([X_test[cat_names], X_test_cont], axis = 1)\n# print(X_all.head()) print(X_test_all.head())\n# X_all.shape, X_test_all.shape\n\n## --- alternate way to scale only dependent variable ---\n# max_price =max(df['Low_Cap_Price'])\n# min_price =min(df['Low_Cap_Price'])\n# df['Low_Cap_Price'] = df['Low_Cap_Price'].apply(lambda x: (x-min_price)/(max_price-min_price))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Declare how you want to \n* Handle Missing Values\n* Handle Categorical Features\n* Normalize Continuous Features<br>\n\nFastAi does this for us.. we need to just mention the procs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dep_var = 'Low_Cap_Price'\n# cat_names = ['State_of_Country', 'Market_Category', 'Product_Category', 'Grade','Month',\t'Dayofweek']\n# cont_names = ['Demand', 'High_Cap_Price']\nprocs = [FillMissing, Categorify, Normalize]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_all = pd.concat([X_all, y], axis = 1)\ndf_all = pd.concat([X, y], axis = 1)\nX_test_all = X_test\nprint(df_all.shape)\ndf_all.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating databunch\n#### This includes both independent features as well as dependent features\n#### This also takes care of pre-processing the validation & the test inputs if included"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = TabularList.from_df(X_test_all, \n                           cat_names = cat_names, \n                           cont_names = cont_names, procs = procs)\n\ndata = (TabularList.from_df(df_all, cat_names = cat_names, cont_names = cont_names, procs = procs)\n                           .split_by_rand_pct(0.10) # .split_none()\n                           .label_from_df(cols = dep_var, label_cls = FloatList, log = True)\n                           .add_test(test)\n                           .databunch()) #bs = 1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.test_ds)\nlen(data.train_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# explore the data\ndata.show_batch(rows = 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some Tweaks before Model Training\nIn regression problems, we can set the max_y to something greater than the current range<br>\nElse, y_pred will always lie within the existing range of y<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_y = np.log(np.max(df_all['Low_Cap_Price'])*1.2)\ny_range = torch.tensor([0, max_y], device=defaults.device)\ny_range","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Initializing Tabular_Learner Model\n#### Set necessary parameters including layers, nodes, regularization, etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initializing the network\nlearn = tabular_learner(data, layers=[1000,500], y_range=y_range, metrics= exp_rmspe, ps = [0.001, 0.01], emb_drop=0.04, callback_fns=ShowGraph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr =1e-3\nmod_name=\"stage1\"\n# smaller rate with smaller steps\nlearn.fit_one_cycle(12, max_lr = slice(1e-2), wd = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  higher learn-rate \n#learn.fit_one_cycle(4, lr)\n\n# smaller rate \n#learn.fit_one_cycle(6, lr/20)\n\n# plot losses\nlearn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# smaller rate \n#learn.fit_one_cycle(6, lr/20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_final = pd.DataFrame(columns=['Item_Id', 'Low_Cap_Price'])\n\n#for index, row in X_test.iterrows():\n # df_final.loc[index] =[row['Item_Id'],float(learn.predict(row)[1])]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using the above model to predict on the test cases\n#### Post processing of results like exp(results) are done if log(y) was considered\n#### submission output file is updated"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = learn.get_preds(ds_type=DatasetType.Test)[0]\ntest_predictions = [i[0] for i in test_predictions.tolist()]\ntest_predictions = pd.DataFrame(test_predictions, columns =['Low_Cap_Price'])\ntest_predictions = np.exp(test_predictions)\ntest_predictions.head()\n#predictions.to_excel(\"Fast_ai_solution.xlsx\", index = False)\n\n#preds, _ = learn.get_preds(ds_type=DatasetType.Test) \n#labels = np.argmax(preds, 1)\n#test_predictions_direct = [data.classes[int(x)] for x in labels]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file = pd.read_csv('/kaggle/input/Test.csv')\nsubmission_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file = submission_file[['Item_Id']]\n#submission_file.Low_Cap_Price = na\nsubmission_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file['Low_Cap_Price'] = test_predictions.Low_Cap_Price\nsubmission_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file.to_csv(\"hacker-earth_pricePrediction_op_v2.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}